# toxicity_bio_project
predicting toxic and non toxic 
To create and evaluate computer models, we used a publicly available toxicity dataset that included molecular structures and their associated toxicity levels. The collection includes important molecular properties such as molecular weight, hydrophobicity, and the number of hydrogen bond donors and acceptors, all of which are required to estimate chemical toxicity.To increase data integrity, we deleted duplicate records as well as instances of missing or inconsistent data during the preparation step. We selected significant chemical descriptors and used normalization to guarantee that each feature had the same effect on model training. To conform with machine learning algorithms, toxicity levels, labeled "toxic" or "non-toxic," were converted into numerical numbers. To preserve the class distribution, we stratified sampled the dataset into two subsets: 70% for training and 30% for testing.

Four machine learning algorithms were employed to forecast the toxicity of chemical pollutants. The Support Vector Machine (SVM) identified compounds as dangerous or non-toxic by locating an ideal hyperplane in a high-dimensional space, and radial basis function (RBF) kernels improved model performance.The k-Nearest Neighbors (KNN) technique identified molecules according to their structural similarities.Self-Organizing Neural Networks (SNN) used unsupervised learning to classify compounds with similar structural features, which were then analyzed for toxicity patterns. Random Forest, an ensemble technique, trained many decision trees to classify molecules based on the majority of their predictions. 

All algorithms were trained using the training dataset, and performance was improved by hyperparameter tuning with grid search and cross-validation. Model performance was evaluated using metrics like accuracy, precision, recall, F1 score, and area under the receiver operating characteristic curve (AUC-ROC). The models' capacity to generalize was assessed by predicting the toxicity of molecular structures not found in the training dataset.
These structures, represented by the SMILES (Simplified Molecular Input Line Entry System) notation, were translated into molecular descriptors using RDKit.

The models were evaluated for their accuracy and precision in differentiating toxic from non-toxic substances, their capacity to handle imbalanced datasets, and their scalability for bigger datasets and new data. Same procedure was done but with the hybrid model using all the four algorithms. Python was used to prepare data, train models, and evaluate performance, while RDKit was utilized to extract molecular descriptors from SMILES representations. Scikit-learn was used to build the machine learning models, and the results were examined and compared with Matplotlib and Seaborn.

Finally, the prediction models were evaluated for their potential environmental applications. These models are meant to help environmentalists and politicians by providing actionable insights into mitigating the negative effects of toxic pollutants on biodiversity and ecosystems, allowing for more effective conservation and management measures.
